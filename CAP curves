mport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
def cumulative_accuracy_profile(y_true, predictions_df):
    plt.figure(figsize=(12, 10))
    
    # Calculate the total population and number of positive cases
    total_population = len(y_true)
    total_positives = np.sum(y_true)
    
    # Calculate the random model line
    random_x = np.linspace(0, 1, 100)
    random_y = random_x
    
    # Calculate the perfect model line
    perfect_x = np.concatenate([[0], np.repeat(total_positives / total_population, 2), [1]])
    perfect_y = np.concatenate([[0], [0, 1], [1]])
    
    # Plot the random and perfect model lines
    plt.plot(random_x, random_y, 'r--', label='Random Model')
    plt.plot(perfect_x, perfect_y, 'g--', label='Perfect Model')
    
    # Colors for different models
    colors = ['b', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown', 'pink', 'gray']
    
    auc_scores = {}
    
    # Plot each model
    for i, column in enumerate(predictions_df.columns):
        y_pred = predictions_df[column]
        
        # Calculate the ROC curve
        fpr, tpr, _ = roc_curve(y_true, y_pred)
        
        # Plot the model line
        plt.plot(fpr, tpr, color=colors[i % len(colors)], label=f'{column}')
        
        # Calculate the area under the curve (AUC)
        auc = np.trapz(tpr, fpr)
        auc_scores[column] = auc
    
    plt.xlabel('Cumulative % of Population')
    plt.ylabel('Cumulative % of Positives')
    plt.title('Cumulative Accuracy Profile Comparison')
    plt.legend()
    plt.grid(True)
    
    # Set the axes to show percentages
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0%}'.format(x)))
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
    
    return plt, auc_scores
